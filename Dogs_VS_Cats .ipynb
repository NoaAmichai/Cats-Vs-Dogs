{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6e7aab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm \n",
    "\n",
    "np.set_printoptions(precision=3)#show 3 number after decimal point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1ac6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = r\"C:\\Users\\noa12\\OneDrive\\מסמכים\\GitHub\\Dogs_Vs_Cats_Project\\train\"\n",
    "TEST_DIR = r\"C:\\Users\\noa12\\OneDrive\\מסמכים\\GitHub\\Dogs_Vs_Cats_Project\\test\"\n",
    "IMG_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e0d3862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    # conversion to one-hot array [cat,dog]\n",
    "    if word_label == 'cat': return [0]\n",
    "    elif word_label == 'dog': return [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3b3445aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(\"train\\\\\",img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1fe1a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(\"test\\\\\",img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e91098a0",
   "metadata": {},
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "184ab24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have already created the dataset:\n",
    "train_data = np.load('train_data.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78ef6982",
   "metadata": {},
   "source": [
    "test_data = process_test_data()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cfbf5cf",
   "metadata": {},
   "source": [
    "test_data = np.load('test_data.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5e31261",
   "metadata": {},
   "source": [
    "X_test = np.array([i[0] for i in test_data])/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c48d9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train_data])\n",
    "Y = np.array([i[1] for i in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac0466db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1063a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aa704089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (20000, 50, 50)\n",
      "y_train.shape : (20000, 1)\n",
      "X_test.shape : (5000, 50, 50)\n",
      "y_test.shape : (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape :\" ,X_train.shape)\n",
    "print(\"y_train.shape :\", y_train.shape)\n",
    "print (\"X_test.shape :\" , X_test.shape)\n",
    "print(\"y_test.shape :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7dac3ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (20000, 2500)\n",
      "X_test.shape : (5000, 2500)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((20000, 50*50))\n",
    "X_test = X_test.reshape((5000,50*50))\n",
    "print(\"X_train.shape :\" ,X_train.shape)\n",
    "print (\"X_test.shape :\" , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "896c74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0:\"cat\", 1:\"dog\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c86320cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train : {0: 10018, 1: 9982}\n",
      "y_test : {0: 2482, 1: 2518}\n"
     ]
    }
   ],
   "source": [
    "#check that the data is balanced\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"y_train :\", dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"y_test :\", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "667ea03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DummyClassifier score is: 0.4964\n"
     ]
    }
   ],
   "source": [
    "# Before we try real models, we will try a dummyClassifier. we will try to get high score than the dummyModel.\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "print(\"The DummyClassifier score is:\" ,accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73144531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "13a64f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ced99274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\noa12\\AppData\\Local\\Temp/ipykernel_32652/4192997717.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  models[key].fit(X_train, y_train)\n",
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    # Fit the classifier model\n",
    "    models[key].fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction \n",
    "    predictions = models[key].predict(X_test)\n",
    "    \n",
    "    # Calculate Accuracy, Precision and Recall Metrics\n",
    "    accuracy[key] = accuracy_score(predictions, y_test)\n",
    "    precision[key] = precision_score(predictions, y_test)\n",
    "    recall[key] = recall_score(predictions, y_test)\n",
    "#With all metrics stored, we can use the pandas library to view the data as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16bc7156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.594917</td>\n",
       "      <td>0.529142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.822478</td>\n",
       "      <td>0.513896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.4966</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.4964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.241859</td>\n",
       "      <td>0.489550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy  Precision    Recall\n",
       "Logistic Regression        0.5294   0.594917  0.529142\n",
       "Support Vector Machines    0.5188   0.822478  0.513896\n",
       "Decision Trees             0.4946   0.001986  0.263158\n",
       "Random Forest              0.4966   0.000397  1.000000\n",
       "Naive Bayes                0.4964   0.000000  0.000000\n",
       "K-Nearest Neighbor         0.4912   0.241859  0.489550"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea64241a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0930d5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\noa12\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:11:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "XGB = XGBClassifier().fit(X_train, y_train)\n",
    "y_pred = XGB.predict(X_test)\n",
    "\n",
    "precision = round(metrics.precision_score(y_test, y_pred, average=\"weighted\"),3)            \n",
    "accuracy = round(metrics.accuracy_score(y_test, y_pred),3)\n",
    "print(\"precision_score:\", precision)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report: \\n\", metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b461620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
